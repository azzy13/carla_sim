{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: carla in /home/azzy13/anaconda3/envs/carla/lib/python3.8/site-packages (0.9.15)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: opencv-python in /home/azzy13/anaconda3/envs/carla/lib/python3.8/site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /home/azzy13/anaconda3/envs/carla/lib/python3.8/site-packages (from opencv-python) (1.18.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pygame in /home/azzy13/anaconda3/envs/carla/lib/python3.8/site-packages (2.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install carla \n",
    "%pip install opencv-python\n",
    "%pip install pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.0 (SDL 2.28.4, Python 3.8.19)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "# Import the CARLA Python API library \n",
    "import carla\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import queue\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pygame\n",
    "from PIL import Image\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the client and get the world object\n",
    "client = carla.Client('localhost', 2000) \n",
    "client.set_timeout(200.0)\n",
    "world  = client.reload_world()\n",
    "bp_lib = world.get_blueprint_library()\n",
    "spawn_points = world.get_map().get_spawn_points() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#small town with rain and river\n",
    "#client.load_world('Town01')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WeatherParameters(cloudiness=30.000000, precipitation=70.000000, precipitation_deposits=0.000000, wind_intensity=0.000000, sun_azimuth_angle=0.000000, sun_altitude_angle=70.000000, fog_density=0.000000, fog_distance=0.000000, fog_falloff=0.000000, wetness=0.000000, scattering_intensity=0.000000, mie_scattering_scale=0.000000, rayleigh_scattering_scale=0.033100, dust_storm=0.000000)\n"
     ]
    }
   ],
   "source": [
    "#change weather to rainy\n",
    "weather = carla.WeatherParameters(\n",
    "    cloudiness=30.0,\n",
    "    precipitation=70.0,\n",
    "    sun_altitude_angle=70.0)\n",
    "\n",
    "world.set_weather(weather)\n",
    "\n",
    "print(world.get_weather())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for bp in world.get_blueprint_library().filter('vehicle'):\n",
    "    #print(bp.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10842"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up the simulator in synchronous mode\n",
    "settings = world.get_settings()\n",
    "settings.synchronous_mode = True # Enables synchronous mode\n",
    "settings.fixed_delta_seconds = 0.05\n",
    "world.apply_settings(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the blueprint for the vehicle you want\n",
    "vehicle_bp = bp_lib.find('vehicle.nissan.patrol_2021') \n",
    "\n",
    "# Try spawning the vehicle at a randomly chosen spawn point\n",
    "vehicle = world.try_spawn_actor(vehicle_bp, random.choice(spawn_points))\n",
    "spectator = world.get_spectator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the spectator behind the vehicle \n",
    "#spectator = world.get_spectator() \n",
    "#transform = carla.Transform(vehicle.get_transform().transform(carla.Location(x=-4,z=2.5)),vehicle.get_transform().rotation) \n",
    "#spectator.set_transform(transform) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spawn vehicles\n",
    "for i in range(50): \n",
    "    vehicle_bp = random.choice(bp_lib.filter('vehicle')) \n",
    "    npc = world.try_spawn_actor(vehicle_bp, random.choice(spawn_points)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the all vehicles in motion using the Traffic Manager\n",
    "#for v in world.get_actors().filter('*vehicle*'): \n",
    "#    v.set_autopilot(True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spawn an RGB cammera with an offset from the vehicle center\n",
    "#camera_bp = bp_lib.find('sensor.camera.rgb') \n",
    "#camera_init_trans = carla.Transform(vehicle.get_transform().transform(carla.Location(x=-4,z=2.5)),vehicle.get_transform().rotation) \n",
    "#camera = world.spawn_actor(camera_bp, camera_init_trans, attach_to=vehicle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntraffic_light = world.get_actors().filter('traffic.traffic_light')[3]\\nprint(traffic_light)  \\np0 = traffic_light.get_transform()\\ncamera_traffic = bp_lib.find('sensor.camera.rgb')\\n# Modify the attributes of the blueprint to set image resolution and field of view.\\n#camera_traffic.set_attribute('image_size_x', '1920')\\n#camera_traffic.set_attribute('image_size_y', '1080')\\ncamera_traffic.set_attribute('fov', '110')\\n# Set the time in seconds between sensor captures\\ncamera_traffic.set_attribute('sensor_tick', '2.0')\\ncamera = world.spawn_actor(camera_traffic, p0, attach_to=traffic_light)\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# camera on traffic lights\n",
    "'''\n",
    "traffic_light = world.get_actors().filter('traffic.traffic_light')[3]\n",
    "print(traffic_light)  \n",
    "p0 = traffic_light.get_transform()\n",
    "camera_traffic = bp_lib.find('sensor.camera.rgb')\n",
    "# Modify the attributes of the blueprint to set image resolution and field of view.\n",
    "#camera_traffic.set_attribute('image_size_x', '1920')\n",
    "#camera_traffic.set_attribute('image_size_y', '1080')\n",
    "camera_traffic.set_attribute('fov', '110')\n",
    "# Set the time in seconds between sensor captures\n",
    "camera_traffic.set_attribute('sensor_tick', '2.0')\n",
    "camera = world.spawn_actor(camera_traffic, p0, attach_to=traffic_light)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location(x=14.000000, y=29.000000, z=6.000000) Rotation(pitch=0.000000, yaw=1.570796, roll=0.000000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: sensor object went out of the scope but the sensor is still alive in the simulation: Actor 90 (sensor.camera.rgb) \n"
     ]
    }
   ],
   "source": [
    "#camera on spectator (drone)\n",
    "#drone = world.get_spectator()\n",
    "#transform = drone.get_transform()\n",
    "#location = transform.location\n",
    "#rotation = transform.rotation\n",
    "location = carla.Location(x=14.0, y=29.0, z=6.0)\n",
    "rotation = carla.Rotation(pitch=0.0, yaw=math.pi/2, roll=0.0)\n",
    "transform = carla.Transform(location, rotation)\n",
    "print(location, rotation)\n",
    "# Set the spectator with an empty transform\n",
    "#drone.set_transform(carla.Transform())\n",
    "\n",
    "camera_drone = bp_lib.find('sensor.camera.rgb')\n",
    "camera_drone.set_attribute('image_size_x', '1920')\n",
    "camera_drone.set_attribute('image_size_y', '1080')\n",
    "camera_drone.set_attribute('sensor_tick', '1.0')\n",
    "camera_drone.set_attribute('fov', '110')\n",
    "camera = world.spawn_actor(camera_drone, transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instance segmentation camera on drone\n",
    "# drone = world.get_spectator()\n",
    "# transform = drone.get_transform()\n",
    "# location = transform.location\n",
    "# rotation = transform.rotation\n",
    "# # Set the spectator with an empty transform\n",
    "# drone.set_transform(carla.Transform())\n",
    "\n",
    "seg_camera = bp_lib.find('sensor.camera.instance_segmentation')\n",
    "seg_camera.set_attribute('image_size_x', '1920')\n",
    "seg_camera.set_attribute('image_size_y', '1080')\n",
    "seg_camera.set_attribute('sensor_tick', '1.0')\n",
    "seg_camera.set_attribute('fov', '110')\n",
    "segmentation_camera = world.spawn_actor(seg_camera, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #semantic lidar on drone\n",
    "# drone = world.get_spectator()\n",
    "# transform = drone.get_transform()\n",
    "# location = transform.location\n",
    "# rotation = transform.rotation\n",
    "# # Set the spectator with an empty transform\n",
    "# drone.set_transform(carla.Transform())\n",
    "\n",
    "sem_lidar = bp_lib.find('sensor.lidar.ray_cast_semantic')\n",
    "sem_lidar.set_attribute('sensor_tick', '1.0')\n",
    "lidar = world.spawn_actor(sem_lidar, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print lidar data\n",
    "def semantic_lidar_data(point_cloud_data):\n",
    "  for detection in point_cloud_data:\n",
    "    print(detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the camera saving data to disk (rgb)\n",
    "#camera.listen(lambda image: image.save_to_disk('dataset/stationary_camera/rgb/%06d.png' % image.frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save segmented images\n",
    "#segmentation_camera.listen(lambda image: image.save_to_disk('dataset/stationary_camera/seg_cam/%06d.png' % image.frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Lidar info\n",
    "#lidar.listen(lambda point_cloud_data: semantic_lidar_data(point_cloud_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#camera.stop()\n",
    "#segmentation_camera.stop()\n",
    "#lidar.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Camera geometric projection -> 3D points\n",
    "def build_projection_matrix(w, h, fov, is_behind_camera=False):\n",
    "    focal = w / (2.0 * np.tan(fov * np.pi / 360.0))\n",
    "    K = np.identity(3)\n",
    "\n",
    "    if is_behind_camera:\n",
    "        K[0, 0] = K[1, 1] = -focal\n",
    "    else:\n",
    "        K[0, 0] = K[1, 1] = focal\n",
    "\n",
    "    K[0, 2] = w / 2.0\n",
    "    K[1, 2] = h / 2.0\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3D to 2D\n",
    "def get_image_point(loc, K, w2c):\n",
    "        # Calculate 2D projection of 3D coordinate\n",
    "\n",
    "        # Format the input coordinate (loc is a carla.Position object)\n",
    "        point = np.array([loc.x, loc.y, loc.z, 1])\n",
    "        # transform to camera coordinates\n",
    "        point_camera = np.dot(w2c, point)\n",
    "\n",
    "        # New we must change from UE4's coordinate system to an \"standard\"\n",
    "        # (x, y ,z) -> (y, -z, x)\n",
    "        # and we remove the fourth componebonent also\n",
    "        point_camera = [point_camera[1], -point_camera[2], point_camera[0]]\n",
    "\n",
    "        # now project 3D->2D using the camera matrix\n",
    "        point_img = np.dot(K, point_camera)\n",
    "        # normalize\n",
    "        point_img[0] /= point_img[2]\n",
    "        point_img[1] /= point_img[2]\n",
    "\n",
    "        return point_img[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the world to camera matrix\n",
    "world_2_camera = np.array(camera.get_transform().get_inverse_matrix())\n",
    "\n",
    "# Get the attributes from the camera\n",
    "image_w = camera_drone.get_attribute(\"image_size_x\").as_int()\n",
    "image_h = camera_drone.get_attribute(\"image_size_y\").as_int()\n",
    "fov = camera_drone.get_attribute(\"fov\").as_float()\n",
    "\n",
    "# Calculate the camera projection matrix to project from 3D -> 2D\n",
    "K = build_projection_matrix(image_w, image_h, fov)\n",
    "K_b = build_projection_matrix(image_w, image_h, fov, is_behind_camera=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_queue = queue.Queue()\n",
    "camera.listen(image_queue.put)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "No image!\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "width = 1920\n",
    "height = 1080\n",
    "seg_camera.set_attribute('image_size_y', '1080')\n",
    "\n",
    "pygame.init()\n",
    "window = pygame.display.set_mode(size=(width,height))\n",
    "font = pygame.font.SysFont(None, 24)\n",
    "video_surf = None\n",
    "\n",
    "world.tick()\n",
    "# Set the all vehicles in motion using the Traffic Manager\n",
    "for v in world.get_actors().filter('*vehicle*'): \n",
    "    v.set_autopilot(True)\n",
    "\n",
    "'''\n",
    "simulation_dataset = {\n",
    "\n",
    "    \"images\": [...,\n",
    "        {\n",
    "        \"file_name\": \"023235.png\",\n",
    "        \"height\": 600,\n",
    "        \"width\": 800,\n",
    "        \"id\": 23235\n",
    "    },\n",
    "    ],\n",
    "\n",
    "    \"annotations\": [\n",
    "        ...,\n",
    "        {\n",
    "            \"image_id\": 23235,\n",
    "            \"bbox\": [503.3, 310.4, 118.3, 78.3]\n",
    "        },\n",
    "        ...\n",
    "    ]\n",
    "}\n",
    "'''\n",
    "simulation_dataset = {}\n",
    "simulation_dataset[\"images\"] = []\n",
    "simulation_dataset[\"annotations\"] = []\n",
    "\n",
    "#render 2D bboxes\n",
    "running = True\n",
    "tick = 0\n",
    "max_tick = 12000\n",
    "while running:\n",
    "    tick = tick + 1\n",
    "    print(tick)\n",
    "    if (tick > max_tick):\n",
    "        break\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            running = False\n",
    "    # Retrieve and reshape the image\n",
    "    world.tick()\n",
    "    image = None\n",
    "    try:\n",
    "        image = image_queue.get(timeout=1)\n",
    "        print(\"Received image!\")\n",
    "    except:\n",
    "        print(\"No image!\")\n",
    "        continue\n",
    "\n",
    "    img = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))\n",
    "    img_filename = 'dataset/stationary_camera/rgb/%06d.png' % image.frame\n",
    "    img_bgr = img[:,:, :3]\n",
    "    #print(img_bg)\n",
    "    img_rgb = img_bgr[:,:, ::-1]\n",
    "    img_PIL = Image.fromarray(img_rgb)\n",
    "    img_PIL.save(img_filename)\n",
    "    simulation_dataset[\"images\"].append({\n",
    "        \"file_name\": img_filename,\n",
    "        \"height\": 1920,\n",
    "        \"width\": 1080,\n",
    "        \"id\": image.frame\n",
    "    })\n",
    "\n",
    "    # Get the camera matrix \n",
    "    world_2_camera = np.array(camera.get_transform().get_inverse_matrix())\n",
    "\n",
    "    for npc in world.get_actors().filter('*vehicle*'):\n",
    "\n",
    "        # Filter out the ego vehicle\n",
    "        if npc.id != vehicle.id:\n",
    "\n",
    "            bb = npc.bounding_box\n",
    "            dist = npc.get_transform().location.distance(transform.location)\n",
    "\n",
    "            # Filter for the vehicles within 50m\n",
    "            if dist < 70:\n",
    "\n",
    "            # Calculate the dot product between the forward vector\n",
    "            # of the vehicle and the vector between the vehicle\n",
    "            # and the other vehicle. We threshold this dot product\n",
    "            # to limit to drawing bounding boxes IN FRONT OF THE CAMERA\n",
    "                forward_vec = transform.get_forward_vector()\n",
    "                ray = npc.get_transform().location - transform.location\n",
    "\n",
    "                if forward_vec.dot(ray) > 0:\n",
    "                    p1 = get_image_point(bb.location, K, world_2_camera)\n",
    "                    verts = [v for v in bb.get_world_vertices(npc.get_transform())]\n",
    "                    x_max = -10000\n",
    "                    x_min = 10000\n",
    "                    y_max = -10000\n",
    "                    y_min = 10000\n",
    "\n",
    "                    for vert in verts:\n",
    "                        p = get_image_point(vert, K, world_2_camera)\n",
    "                        # Find the rightmost vertex\n",
    "                        if p[0] > x_max:\n",
    "                            x_max = p[0]\n",
    "                        # Find the leftmost vertex\n",
    "                        if p[0] < x_min:\n",
    "                            x_min = p[0]\n",
    "                        # Find the highest vertex\n",
    "                        if p[1] > y_max:\n",
    "                            y_max = p[1]\n",
    "                        # Find the lowest  vertex\n",
    "                        if p[1] < y_min:\n",
    "                            y_min = p[1]\n",
    "\n",
    "                    cv2.line(img, (int(x_min),int(y_min)), (int(x_max),int(y_min)), (0,0,255, 255), 1)\n",
    "                    cv2.line(img, (int(x_min),int(y_max)), (int(x_max),int(y_max)), (0,0,255, 255), 1)\n",
    "                    cv2.line(img, (int(x_min),int(y_min)), (int(x_min),int(y_max)), (0,0,255, 255), 1)\n",
    "                    cv2.line(img, (int(x_max),int(y_min)), (int(x_max),int(y_max)), (0,0,255, 255), 1)\n",
    "                    bbox = [x_min, y_min, x_max, y_max]\n",
    "                    rounded_bbox = [round(value) for value in bbox]\n",
    "                    print(rounded_bbox)\n",
    "                    simulation_dataset[\"annotations\"].append({\n",
    "                        \"image_id\": image.frame,\n",
    "                        \"bbox\": rounded_bbox\n",
    "                    })\n",
    "\n",
    "    video_surf = pygame.image.frombuffer(img, (image.width, image.height), \"BGRA\")\n",
    "    window.blit(video_surf, (0,0))\n",
    "    pygame.display.flip()\n",
    "    #pygame.time.wait(5)\n",
    "pygame.quit()\n",
    "\n",
    "with open('simulation_data.json', 'w') as json_file:\n",
    "    json.dump(simulation_dataset, json_file)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location(x=0.028380, y=0.000002, z=1.016716)\n",
      "Vector3D(x=2.782914, y=1.074983, z=1.022574)\n"
     ]
    }
   ],
   "source": [
    "# box = vehicle.bounding_box\n",
    "# print(box.location)         # Location relative to the vehicle.\n",
    "# print(box.extent)\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
