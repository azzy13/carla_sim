{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: carla in /home/azzy13/anaconda3/envs/carla/lib/python3.8/site-packages (0.9.15)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: opencv-python in /home/azzy13/anaconda3/envs/carla/lib/python3.8/site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /home/azzy13/anaconda3/envs/carla/lib/python3.8/site-packages (from opencv-python) (1.24.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pygame in /home/azzy13/anaconda3/envs/carla/lib/python3.8/site-packages (2.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install carla \n",
    "%pip install opencv-python\n",
    "%pip install pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.0 (SDL 2.28.4, Python 3.8.19)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "# Import the CARLA Python API library \n",
    "import carla\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import queue\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pygame\n",
    "from PIL import Image\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the client and get the world object\n",
    "client = carla.Client('localhost', 2000) \n",
    "client.set_timeout(200.0)\n",
    "world  = client.reload_world()\n",
    "bp_lib = world.get_blueprint_library()\n",
    "spawn_points = world.get_map().get_spawn_points() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WeatherParameters(cloudiness=40.000000, precipitation=100.000000, precipitation_deposits=0.000000, wind_intensity=0.000000, sun_azimuth_angle=0.000000, sun_altitude_angle=70.000000, fog_density=0.000000, fog_distance=0.000000, fog_falloff=0.000000, wetness=0.000000, scattering_intensity=0.000000, mie_scattering_scale=0.000000, rayleigh_scattering_scale=0.033100, dust_storm=0.000000)\n"
     ]
    }
   ],
   "source": [
    "##change weather to rainy\n",
    "weather = carla.WeatherParameters(\n",
    "    cloudiness=30.0,\n",
    "    precipitation=70.0,\n",
    "    sun_altitude_angle=70.0)\n",
    "\n",
    "world.set_weather(weather)\n",
    "\n",
    "print(world.get_weather())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: synchronous mode enabled with variable delta seconds. It is highly recommended to set 'fixed_delta_seconds' when running on synchronous mode. \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "215724"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set up the simulator in synchronous mode\n",
    "settings = world.get_settings()\n",
    "settings.synchronous_mode = True # Enables synchronous mode\n",
    "settings.fixed_delta_seconds = 0.04\n",
    "world.apply_settings(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the blueprint for the vehicle you want\n",
    "vehicle_bp = bp_lib.find('vehicle.nissan.patrol_2021') \n",
    "\n",
    "# Try spawning the vehicle at a randomly chosen spawn point\n",
    "vehicle = world.try_spawn_actor(vehicle_bp, random.choice(spawn_points))\n",
    "spectator = world.get_spectator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the spectator behind the vehicle \n",
    "#spectator = world.get_spectator() \n",
    "#transform = carla.Transform(vehicle.get_transform().transform(carla.Location(x=-4,z=2.5)),vehicle.get_transform().rotation) \n",
    "#spectator.set_transform(transform) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spawn vehicles\n",
    "for i in range(50): \n",
    "    vehicle_bp = random.choice(bp_lib.filter('vehicle')) \n",
    "    npc = world.try_spawn_actor(vehicle_bp, random.choice(spawn_points)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the all vehicles in motion using the Traffic Manager\n",
    "#for v in world.get_actors().filter('*vehicle*'): \n",
    "#    v.set_autopilot(True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#camera on spectator (drone)\n",
    "#drone = world.get_spectator()\n",
    "#transform = drone.get_transform()\n",
    "#location = transform.location\n",
    "#rotation = transform.rotation\n",
    "#Set 1 - Location(x=-57.660717, y=-71.480591, z=9.112691) Rotation(pitch=-8.841427, yaw=42.202526, roll=0.000119)\n",
    "#Set 2 - Location(x=103.583794, y=133.276993, z=8.625797) Rotation(pitch=-13.471584, yaw=-178.655457, roll=0.000182)\n",
    "#location = carla.Location(x=14.0, y=29.0, z=6.0)\n",
    "#rotation = carla.Rotation(pitch=0.0, yaw=math.pi/2, roll=0.0)\n",
    "location = carla.Location(x=103.583794, y=133.276993, z=8.625797)\n",
    "rotation = carla.Rotation(pitch=-13.471584, yaw=-178.655457, roll=0.000182)\n",
    "transform = carla.Transform(location, rotation)\n",
    "# Set the spectator with an empty transform\n",
    "#drone.set_transform(carla.Transform())\n",
    "\n",
    "camera_drone = bp_lib.find('sensor.camera.rgb')\n",
    "camera_drone.set_attribute('image_size_x', '1920')\n",
    "camera_drone.set_attribute('image_size_y', '1080')\n",
    "camera_drone.set_attribute('sensor_tick', '1.0')\n",
    "camera_drone.set_attribute('fov', '110')\n",
    "camera = world.spawn_actor(camera_drone, transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instance segmentation camera on drone\n",
    "# drone = world.get_spectator()\n",
    "# transform = drone.get_transform()\n",
    "# location = transform.location\n",
    "# rotation = transform.rotation\n",
    "# # Set the spectator with an empty transform\n",
    "# drone.set_transform(carla.Transform())\n",
    "\n",
    "seg_camera = bp_lib.find('sensor.camera.instance_segmentation')\n",
    "seg_camera.set_attribute('image_size_x', '1920')\n",
    "seg_camera.set_attribute('image_size_y', '1080')\n",
    "seg_camera.set_attribute('sensor_tick', '1.0')\n",
    "seg_camera.set_attribute('fov', '110')\n",
    "segmentation_camera = world.spawn_actor(seg_camera, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #semantic lidar on drone\n",
    "# drone = world.get_spectator()\n",
    "# transform = drone.get_transform()\n",
    "# location = transform.location\n",
    "# rotation = transform.rotation\n",
    "# # Set the spectator with an empty transform\n",
    "# drone.set_transform(carla.Transform())\n",
    "\n",
    "sem_lidar = bp_lib.find('sensor.lidar.ray_cast_semantic')\n",
    "sem_lidar.set_attribute('sensor_tick', '1.0')\n",
    "lidar = world.spawn_actor(sem_lidar, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print lidar data\n",
    "def semantic_lidar_data(point_cloud_data):\n",
    "  for detection in point_cloud_data:\n",
    "    print(detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Camera geometric projection -> 3D points\n",
    "def build_projection_matrix(w, h, fov, is_behind_camera=False):\n",
    "    focal = w / (2.0 * np.tan(fov * np.pi / 360.0))\n",
    "    K = np.identity(3)\n",
    "\n",
    "    if is_behind_camera:\n",
    "        K[0, 0] = K[1, 1] = -focal\n",
    "    else:\n",
    "        K[0, 0] = K[1, 1] = focal\n",
    "\n",
    "    K[0, 2] = w / 2.0\n",
    "    K[1, 2] = h / 2.0\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3D to 2D\n",
    "def get_image_point(loc, K, w2c):\n",
    "        # Calculate 2D projection of 3D coordinate\n",
    "\n",
    "        # Format the input coordinate (loc is a carla.Position object)\n",
    "        point = np.array([loc.x, loc.y, loc.z, 1])\n",
    "        # transform to camera coordinates\n",
    "        point_camera = np.dot(w2c, point)\n",
    "\n",
    "        # New we must change from UE4's coordinate system to an \"standard\"\n",
    "        # (x, y ,z) -> (y, -z, x)\n",
    "        # and we remove the fourth componebonent also\n",
    "        point_camera = [point_camera[1], -point_camera[2], point_camera[0]]\n",
    "\n",
    "        # now project 3D->2D using the camera matrix\n",
    "        point_img = np.dot(K, point_camera)\n",
    "        # normalize\n",
    "        point_img[0] /= point_img[2]\n",
    "        point_img[1] /= point_img[2]\n",
    "\n",
    "        return point_img[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the world to camera matrix\n",
    "world_2_camera = np.array(camera.get_transform().get_inverse_matrix())\n",
    "\n",
    "# Get the attributes from the camera\n",
    "image_w = camera_drone.get_attribute(\"image_size_x\").as_int()\n",
    "image_h = camera_drone.get_attribute(\"image_size_y\").as_int()\n",
    "fov = camera_drone.get_attribute(\"fov\").as_float()\n",
    "\n",
    "# Calculate the camera projection matrix to project from 3D -> 2D\n",
    "K = build_projection_matrix(image_w, image_h, fov)\n",
    "K_b = build_projection_matrix(image_w, image_h, fov, is_behind_camera=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_queue = queue.Queue()\n",
    "camera.listen(image_queue.put)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Received image!\n",
      "Image_count: 1\n",
      "[1983, 493, 2158, 534]\n",
      "[-183685, -18346, 5744724, 749211]\n",
      "[-2686991, -228216, 962810, 77458]\n",
      "2\n",
      "No image!\n",
      "3\n",
      "Received image!\n",
      "Image_count: 2\n",
      "[1980, 500, 2154, 542]\n",
      "[-306436, -32767, 404441, 55741]\n",
      "[10000, 2564, 683088, 62110]\n",
      "4\n",
      "No image!\n",
      "5\n",
      "No image!\n",
      "6\n",
      "Received image!\n",
      "Image_count: 3\n",
      "[1979, 503, 2153, 545]\n",
      "[-412425, -45218, 297947, 41912]\n",
      "[10000, 2573, 512392, 47405]\n",
      "7\n",
      "No image!\n",
      "8\n",
      "Received image!\n",
      "Image_count: 4\n",
      "[1982, 503, 2156, 545]\n",
      "[-400545, -43596, 302660, 42322]\n",
      "[10000, 2569, 531842, 48977]\n",
      "9\n",
      "No image!\n",
      "10\n",
      "No image!\n",
      "11\n",
      "Received image!\n",
      "Image_count: 5\n",
      "[1995, 504, 2174, 547]\n",
      "[-467651, -50569, 306335, 42504]\n",
      "[10000, 2561, 505520, 46244]\n",
      "12\n",
      "No image!\n",
      "13\n",
      "Received image!\n",
      "Image_count: 6\n",
      "[2012, 506, 2196, 550]\n",
      "[-574149, -61689, 291385, 40141]\n",
      "[10000, 2553, 472210, 42949]\n",
      "14\n",
      "No image!\n",
      "15\n",
      "No image!\n",
      "16\n",
      "Received image!\n",
      "Image_count: 7\n",
      "[2049, 511, 2246, 557]\n",
      "[-1132462, -119994, 260374, 35298]\n",
      "[10000, 2535, 411431, 36938]\n",
      "17\n",
      "No image!\n",
      "18\n",
      "Received image!\n",
      "Image_count: 8\n",
      "[2081, 514, 2289, 563]\n",
      "[-4418928, -462313, 227027, 30347]\n",
      "[10000, 2519, 372448, 33050]\n",
      "19\n",
      "No image!\n",
      "20\n",
      "No image!\n",
      "21\n",
      "Received image!\n",
      "Image_count: 9\n",
      "[2141, 522, 2372, 574]\n",
      "[-674334, -72670, 999234, 102064]\n",
      "[10000, 2502, 337835, 29555]\n",
      "22\n",
      "No image!\n",
      "23\n",
      "Received image!\n",
      "Image_count: 10\n",
      "[2197, 528, 2451, 584]\n",
      "[-1949867, -205976, 629149, 63092]\n",
      "[10000, 2488, 311820, 27033]\n",
      "24\n",
      "No image!\n",
      "25\n",
      "No image!\n",
      "26\n",
      "Received image!\n",
      "Image_count: 11\n",
      "[2294, 540, 2588, 603]\n",
      "[10000, 2813, 1942843, 200093]\n",
      "[10000, 2470, 287458, 24570]\n",
      "27\n",
      "No image!\n",
      "28\n",
      "Received image!\n",
      "Image_count: 12\n",
      "[2363, 548, 2688, 617]\n",
      "[10000, 2781, 912882, 92588]\n",
      "[10000, 2457, 269806, 22871]\n",
      "29\n",
      "No image!\n",
      "30\n",
      "No image!\n",
      "31\n",
      "Received image!\n",
      "Image_count: 13\n",
      "[2486, 563, 2872, 641]\n",
      "[10000, 2745, 523476, 51867]\n",
      "[10000, 2439, 251084, 20977]\n",
      "32\n",
      "No image!\n",
      "33\n",
      "Received image!\n",
      "Image_count: 14\n",
      "[2580, 574, 3017, 661]\n",
      "[10000, 2723, 434567, 42483]\n",
      "[10000, 2415, 242369, 20087]\n",
      "34\n",
      "No image!\n",
      "35\n",
      "No image!\n",
      "36\n",
      "Received image!\n",
      "Image_count: 15\n",
      "[2741, 594, 3274, 695]\n",
      "[10000, 2694, 359430, 34567]\n",
      "[10000, 2376, 220527, 18014]\n",
      "37\n",
      "No image!\n",
      "38\n",
      "Received image!\n",
      "Image_count: 16\n",
      "[2870, 610, 3491, 724]\n",
      "[10000, 2677, 316829, 30121]\n",
      "39\n",
      "No image!\n",
      "40\n",
      "No image!\n",
      "41\n",
      "Received image!\n",
      "Image_count: 17\n",
      "[3090, 637, 3888, 779]\n",
      "[10000, 2647, 269465, 25100]\n",
      "42\n",
      "No image!\n",
      "43\n",
      "Received image!\n",
      "Image_count: 18\n",
      "[3266, 659, 4227, 826]\n",
      "[10000, 2625, 249903, 22945]\n",
      "44\n",
      "No image!\n",
      "45\n",
      "No image!\n",
      "46\n",
      "Received image!\n",
      "Image_count: 19\n",
      "[3583, 699, 4894, 921]\n",
      "[10000, 2610, 237658, 21574]\n",
      "47\n",
      "No image!\n",
      "48\n",
      "Received image!\n",
      "Image_count: 20\n",
      "[3827, 731, 5430, 1002]\n",
      "[10000, 2603, 229787, 20781]\n",
      "49\n",
      "No image!\n",
      "50\n",
      "No image!\n",
      "51\n",
      "Received image!\n",
      "Image_count: 21\n",
      "[4248, 789, 6250, 1138]\n",
      "[10000, 2588, 215058, 19261]\n",
      "52\n",
      "No image!\n",
      "53\n",
      "Received image!\n",
      "Image_count: 22\n",
      "[4544, 833, 6672, 1218]\n",
      "[10000, 2575, 203833, 18081]\n",
      "54\n",
      "No image!\n",
      "55\n",
      "No image!\n",
      "56\n",
      "Received image!\n",
      "Image_count: 23\n",
      "[4950, 900, 6653, 1256]\n",
      "[10000, 2553, 197223, 17233]\n",
      "57\n",
      "No image!\n",
      "58\n",
      "Received image!\n",
      "Image_count: 24\n",
      "[5077, 933, 6431, 1251]\n",
      "[10000, 2547, 189320, 16473]\n",
      "59\n",
      "No image!\n",
      "60\n",
      "No image!\n",
      "61\n",
      "Received image!\n",
      "Image_count: 25\n",
      "[4872, 958, 6389, 1247]\n",
      "[10000, 2524, 185665, 15956]\n",
      "62\n",
      "No image!\n",
      "63\n",
      "Received image!\n",
      "Image_count: 26\n",
      "[4753, 966, 6316, 1248]\n",
      "[10000, 2511, 177162, 15071]\n",
      "64\n",
      "No image!\n",
      "65\n",
      "No image!\n",
      "66\n",
      "Received image!\n",
      "Image_count: 27\n",
      "[4574, 972, 6140, 1251]\n",
      "[10000, 2502, 171497, 14481]\n",
      "67\n",
      "No image!\n",
      "68\n",
      "Received image!\n",
      "Image_count: 28\n",
      "[4458, 975, 6006, 1254]\n",
      "[10000, 2492, 166088, 13933]\n",
      "[883, 432, 896, 444]\n",
      "69\n",
      "No image!\n",
      "70\n",
      "No image!\n",
      "71\n",
      "Received image!\n",
      "Image_count: 29\n",
      "[4283, 978, 5792, 1258]\n",
      "[10000, 2472, 157556, 13022]\n",
      "[881, 434, 894, 445]\n",
      "72\n",
      "No image!\n",
      "73\n",
      "Received image!\n",
      "Image_count: 30\n",
      "[4137, 980, 5655, 1253]\n",
      "[880, 435, 893, 447]\n",
      "74\n",
      "No image!\n",
      "75\n",
      "No image!\n",
      "76\n",
      "Received image!\n",
      "Image_count: 31\n",
      "[3927, 975, 5400, 1252]\n",
      "[878, 436, 892, 448]\n",
      "77\n",
      "No image!\n",
      "78\n",
      "Received image!\n",
      "Image_count: 32\n",
      "[3778, 970, 5223, 1250]\n",
      "[877, 437, 891, 450]\n",
      "79\n",
      "No image!\n",
      "80\n",
      "No image!\n",
      "81\n",
      "Received image!\n",
      "Image_count: 33\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/carla/lib/python3.8/site-packages/PIL/ImageFile.py:547\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 547\u001b[0m     fh \u001b[38;5;241m=\u001b[39m \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfileno\u001b[49m()\n\u001b[1;32m    548\u001b[0m     fp\u001b[38;5;241m.\u001b[39mflush()\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_idat' object has no attribute 'fileno'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 50\u001b[0m\n\u001b[1;32m     48\u001b[0m img_rgb \u001b[38;5;241m=\u001b[39m img_bgr[:,:, ::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     49\u001b[0m img_PIL \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img_rgb)\n\u001b[0;32m---> 50\u001b[0m \u001b[43mimg_PIL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_filename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m simulation_dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: img_filename,\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheight\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1920\u001b[39m,\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1080\u001b[39m,\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: image\u001b[38;5;241m.\u001b[39mframe\n\u001b[1;32m     56\u001b[0m })\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Get the camera matrix \u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/carla/lib/python3.8/site-packages/PIL/Image.py:2568\u001b[0m, in \u001b[0;36mImage.save\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2565\u001b[0m     fp \u001b[38;5;241m=\u001b[39m cast(IO[\u001b[38;5;28mbytes\u001b[39m], fp)\n\u001b[1;32m   2567\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2568\u001b[0m     \u001b[43msave_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2569\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   2570\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m open_fp:\n",
      "File \u001b[0;32m~/anaconda3/envs/carla/lib/python3.8/site-packages/PIL/PngImagePlugin.py:1431\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(im, fp, filename, chunk, save_all)\u001b[0m\n\u001b[1;32m   1427\u001b[0m     im \u001b[38;5;241m=\u001b[39m _write_multiple_frames(\n\u001b[1;32m   1428\u001b[0m         im, fp, chunk, mode, rawmode, default_image, append_images\n\u001b[1;32m   1429\u001b[0m     )\n\u001b[1;32m   1430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m im:\n\u001b[0;32m-> 1431\u001b[0m     \u001b[43mImageFile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_idat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrawmode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1433\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info:\n\u001b[1;32m   1434\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m info_chunk \u001b[38;5;129;01min\u001b[39;00m info\u001b[38;5;241m.\u001b[39mchunks:\n",
      "File \u001b[0;32m~/anaconda3/envs/carla/lib/python3.8/site-packages/PIL/ImageFile.py:551\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    549\u001b[0m     _encode_tile(im, fp, tile, bufsize, fh)\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, io\u001b[38;5;241m.\u001b[39mUnsupportedOperation) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m--> 551\u001b[0m     \u001b[43m_encode_tile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbufsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflush\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    553\u001b[0m     fp\u001b[38;5;241m.\u001b[39mflush()\n",
      "File \u001b[0;32m~/anaconda3/envs/carla/lib/python3.8/site-packages/PIL/ImageFile.py:570\u001b[0m, in \u001b[0;36m_encode_tile\u001b[0;34m(im, fp, tile, bufsize, fh, exc)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exc:\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;66;03m# compress to Python file-compatible object\u001b[39;00m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 570\u001b[0m         errcode, data \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbufsize\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    571\u001b[0m         fp\u001b[38;5;241m.\u001b[39mwrite(data)\n\u001b[1;32m    572\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m errcode:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "width = 1920\n",
    "height = 1080\n",
    "\n",
    "pygame.init()\n",
    "window = pygame.display.set_mode(size=(width,height))\n",
    "font = pygame.font.SysFont(None, 24)\n",
    "video_surf = None\n",
    "\n",
    "world.tick()\n",
    "# Set the all vehicles in motion using the Traffic Manager\n",
    "for v in world.get_actors().filter('*vehicle*'): \n",
    "    v.set_autopilot(True)\n",
    "\n",
    "simulation_dataset = {}\n",
    "simulation_dataset[\"images\"] = []\n",
    "simulation_dataset[\"annotations\"] = []\n",
    "\n",
    "#render 2D bboxes\n",
    "running = True\n",
    "tick = 0\n",
    "max_tick = 12000\n",
    "img_cnt = 0\n",
    "while running:\n",
    "    tick = tick + 1\n",
    "    print(tick)\n",
    "    if (tick > max_tick):\n",
    "        break\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            running = False\n",
    "    # Retrieve and reshape the image\n",
    "    world.tick()\n",
    "    image = None\n",
    "    try:\n",
    "        image = image_queue.get(timeout=1)\n",
    "        print(\"Received image!\")\n",
    "        img_cnt += 1\n",
    "        print(f\"Image_count: {img_cnt}\")\n",
    "    except:\n",
    "        print(\"No image!\")\n",
    "        #world.tick()\n",
    "        continue\n",
    "\n",
    "    img = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))\n",
    "    img_filename = 'dataset/stationary_camera/set2/images/%06d.png' % image.frame\n",
    "    img_bgr = img[:,:, :3]\n",
    "    #print(img_bg)\n",
    "    img_rgb = img_bgr[:,:, ::-1]\n",
    "    img_PIL = Image.fromarray(img_rgb)\n",
    "    img_PIL.save(img_filename)\n",
    "    simulation_dataset[\"images\"].append({\n",
    "        \"file_name\": img_filename,\n",
    "        \"height\": 1920,\n",
    "        \"width\": 1080,\n",
    "        \"id\": image.frame\n",
    "    })\n",
    "\n",
    "    # Get the camera matrix \n",
    "    world_2_camera = np.array(camera.get_transform().get_inverse_matrix())\n",
    "\n",
    "    for npc in world.get_actors().filter('*vehicle*'):\n",
    "\n",
    "        # Filter out the ego vehicle\n",
    "        if npc.id != vehicle.id:\n",
    "\n",
    "            bb = npc.bounding_box\n",
    "            dist = npc.get_transform().location.distance(transform.location)\n",
    "\n",
    "            # Filter for the vehicles within 50m\n",
    "            if dist < 85:\n",
    "\n",
    "            # Calculate the dot product between the forward vector\n",
    "            # of the vehicle and the vector between the vehicle\n",
    "            # and the other vehicle. We threshold this dot product\n",
    "            # to limit to drawing bounding boxes IN FRONT OF THE CAMERA\n",
    "                forward_vec = transform.get_forward_vector()\n",
    "                ray = npc.get_transform().location - transform.location\n",
    "\n",
    "                if forward_vec.dot(ray) > 0:\n",
    "                    p1 = get_image_point(bb.location, K, world_2_camera)\n",
    "                    verts = [v for v in bb.get_world_vertices(npc.get_transform())]\n",
    "                    x_max = -10000\n",
    "                    x_min = 10000\n",
    "                    y_max = -10000\n",
    "                    y_min = 10000\n",
    "\n",
    "                    for vert in verts:\n",
    "                        p = get_image_point(vert, K, world_2_camera)\n",
    "                        # Find the rightmost vertex\n",
    "                        if p[0] > x_max:\n",
    "                            x_max = p[0]\n",
    "                        # Find the leftmost vertex\n",
    "                        if p[0] < x_min:\n",
    "                            x_min = p[0]\n",
    "                        # Find the highest vertex\n",
    "                        if p[1] > y_max:\n",
    "                            y_max = p[1]\n",
    "                        # Find the lowest  vertex\n",
    "                        if p[1] < y_min:\n",
    "                            y_min = p[1]\n",
    "\n",
    "                    cv2.line(img, (int(x_min),int(y_min)), (int(x_max),int(y_min)), (0,0,255, 255), 1)\n",
    "                    cv2.line(img, (int(x_min),int(y_max)), (int(x_max),int(y_max)), (0,0,255, 255), 1)\n",
    "                    cv2.line(img, (int(x_min),int(y_min)), (int(x_min),int(y_max)), (0,0,255, 255), 1)\n",
    "                    cv2.line(img, (int(x_max),int(y_min)), (int(x_max),int(y_max)), (0,0,255, 255), 1)\n",
    "                    bbox = [x_min, y_min, x_max, y_max]\n",
    "                    bbox_str = str(bbox)\n",
    "                    rounded_bbox = [round(value) for value in bbox]\n",
    "                    print(rounded_bbox)\n",
    "                    simulation_dataset[\"annotations\"].append({\n",
    "                        \"image_id\": image.frame,\n",
    "                        \"category_id\": 1,\n",
    "                        \"bbox\": rounded_bbox\n",
    "                    })\n",
    "                    bbox_str = '{},{},{},{}'.format(round(x_min), round(y_min), round(x_max), round(y_max))\n",
    "\n",
    "                # Put the bounding box string on the image\n",
    "                #cv2.putText(img, bbox_str, (int(x_min), int(y_min) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "    video_surf = pygame.image.frombuffer(img, (image.width, image.height), \"BGRA\")\n",
    "    window.blit(video_surf, (0,0))\n",
    "    pygame.display.flip()\n",
    "    #pygame.time.wait(5)\n",
    "pygame.quit()\n",
    "\n",
    "with open('simulation_data.json', 'w') as json_file:\n",
    "    json.dump(simulation_dataset, json_file)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
